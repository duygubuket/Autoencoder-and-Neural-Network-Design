# Autoencoder-and-Neural-Network-Design

## ğŸ§  Project Overview

This project involves building and evaluating two deep learning models on the Fashion-MNIST dataset:

1. An **Autoencoder** for image reconstruction and generation.
2. A **Feedforward Neural Network Classifier** for multi-class classification of clothing items.

---

## ğŸ—‚ï¸ Contents

- `autoencoder.py` â€“ Autoencoder architecture and training
- `classifier.py` â€“ Classifier model and training loop
- `utils.py` â€“ Helper functions for data loading and visualization
- `images/` â€“ Contains plots, reconstructions, and confusion matrix

---

## ğŸ› ï¸ Autoencoder Details

### ğŸ”§ Architecture

- **Encoder:**  
  784 â†’ 512 â†’ 256 â†’ 128 â†’ **64 (Latent Space)**
- **Decoder:**  
  64 â†’ 128 â†’ 256 â†’ 512 â†’ 784

### ğŸ§ª Hyperparameters

| Parameter         | Value         |
|------------------|---------------|
| Latent Dimension | 64            |
| Optimizer        | Adam          |
| Learning Rate    | 0.001         |
| Batch Size       | 128           |
| Epochs           | 25            |
| Loss Function    | MSE           |

### ğŸ“Š Performance

- **Final MSE on Test Set:** 0.009931
- **Reconstruction Accuracy:** ~99.01%
- **Visual Quality:** High fidelity with clear structural preservation

### ğŸ” Generation Results

- Random latent vectors were sampled from N(0,1)
- Generated images captured garment structure, though blurry and less diverse
- Suggested improvements: **Variational Autoencoder**, **regularization**, and **FID evaluation**

---

## ğŸ§® Classifier Details

### ğŸ”§ Architecture

- Input: 784 â†’ 512 â†’ 256 â†’ 128 â†’ **Softmax (10 classes)**

### ğŸ§ª Hyperparameters

| Parameter          | Value                    |
|-------------------|--------------------------|
| Loss Function      | CrossEntropyLoss         |
| Optimizer          | Adam                     |
| Learning Rate      | 0.001                    |
| Epochs             | 50                       |
| Dropout Rate       | 0.3                      |
| Weight Decay       | 1e-4                     |
| Scheduler          | StepLR (step=20, Î³=0.5)  |

### âš™ï¸ Regularization

- **Batch Normalization** after each layer
- **Dropout (30%)** to prevent overfitting
- **L2 Regularization**

---

## ğŸ“ˆ Performance

| Metric               | Value     |
|----------------------|-----------|
| Final Test Accuracy  | 90.07%    |
| Training Accuracy    | 96.32%    |
| Best Validation Acc. | 90.94%    |
| F1-Score (Macro Avg) | **0.90**  |

### ğŸ” Confusion Matrix Observations

- **Well-Classified:** Trouser, Bag, Sandal, Ankle Boot
- **Most Confused:** T-shirt â†” Shirt, Pullover â†” Coat
- **Causes of Error:** shape ambiguity, texture similarity, unusual orientations

---

## ğŸ“· Visualizations

- **Train/Val Loss Curves**
- **Reconstructed vs Original Samples**
- **Generated Images**
- **Confusion Matrix**
- **Misclassified Examples**

> All visuals are included in the `images/` folder and `report.pdf`.

---

## ğŸ“Œ Key Insights

- The autoencoder achieved strong reconstructions but weaker generative performance.
- The classifier was effective overall, with ~90% accuracy and challenges in visually similar classes.
- Regularization (dropout, weight decay) helped limit overfitting, but further tuning (e.g., deeper architectures, data augmentation) may enhance results.

---

## ğŸ§‘â€ğŸ’» Author

**Duygu Buket BÄ±yÄ±k**  
ğŸ“§ [duygubuketbiyik@gmail.com](mailto:duygubuketbiyik@gmail.com)  
ğŸŒ [GitHub](https://github.com/duygubuket) | [LinkedIn](https://www.linkedin.com/in/duygubuketbiyik)

---

## ğŸ“‚ License

This project is part of a university homework assignment and intended for academic use only.
